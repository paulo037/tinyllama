{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional,  Tuple\n",
    "from einops import rearrange\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO code load dataset and dataloader\n",
    "# TODO code training loop\n",
    "# TODO code evaluation loop\n",
    "# TODO add support to tensorboard\n",
    "# TODO add weights initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyllama import TinyLlama, name_to_config, load_model_weights\n",
    "tiny_LLaMA_1b = TinyLlama(name_to_config['tiny_LLaMA_1b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_weights(tiny_LLaMA_1b, \"model/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/snapshots/fe8a4ea1ffedaf415f4da2f062534de366a451e6/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True,  map_device=\"auto\", add_eos_token=True, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=\"model\",\n",
    "    # attn_implementation=attn_implementation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ids = tokenizer(\"Hello, how are you?\", return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = tiny_LLaMA_1b(inputs_ids)\n",
    "out2 = model(inputs_ids, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (out1 == out2.logits).all(), \"The model output is different from the reference model output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = [\n",
    "  {'role': 'user', 'content': 'Hello, how are you?'},\n",
    "]\n",
    "\n",
    "inputs_ids = tokenizer.apply_chat_template(chat, return_tensors=\"pt\", tokenize=True, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tiny_LLaMA_1b.generate(inputs_ids, max_length=10, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from huggingface_hub import HfFileSystem\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True,  map_device=\"auto\", add_eos_token=True, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SlimPajama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_folder(model_id, folder_path, repo_type=\"model\", output_dir=\"data\"):\n",
    "\n",
    "    for i in range(50):\n",
    "        file_name = f\"/example_train_{i}.jsonl.zst\"\n",
    "        hf_hub_download(repo_id=model_id, filename=(f'{folder_path}{file_name}'), local_dir=output_dir, repo_type=repo_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_folder(\"cerebras/SlimPajama-627B\", \"train/chunk1\", \"dataset\",  output_dir=\"pre-processing/data/slimpajama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import zstandard as zstd\n",
    "\n",
    "\n",
    "def read_zst_jsonl(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        dctx = zstd.ZstdDecompressor()\n",
    "        \n",
    "        decompressed_data = dctx.stream_reader(f)\n",
    "        return pd.read_json(decompressed_data, lines=True)\n",
    "\n",
    "\n",
    "folder_path = 'data/slimpajama/train/chunk1'\n",
    "\n",
    "\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl.zst')]\n",
    "\n",
    "\n",
    "df = pd.concat([read_zst_jsonl(os.path.join(folder_path, file)) for file in files], ignore_index=True)\n",
    "\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(50000, random_state=42, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids'] = df['text'].apply(lambda x: tokenizer(x, return_tensors=\"pt\").input_ids[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "hf_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "hf_dataset.push_to_hub(\"slimpajama\", token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids_size'] = df['input_ids'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['input_ids_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StarCoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://huggingface.co/datasets/bigcode/starcoderdata/resolve/main/python/train-00000-of-00059.parquet\"\n",
    "output_path = \"pre-processing/data/train-00000-of-00059.parquet\"\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "response = requests.get(url, headers=headers, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f\"File successfully downloaded: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_parquet(\"pre-processing/data/train-00000-of-00059.parquet\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10000, random_state=42, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids'] = df['content'].apply(lambda x: tokenizer(x, return_tensors=\"pt\").input_ids[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_ids_size'] = df['input_ids'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['input_ids_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(df)\n",
    "hf_dataset.push_to_hub(\"starcoder\", token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
